\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{b1}
\citation{b6}
\citation{b1}
\citation{b4}
\citation{b2,b3}
\citation{b5}
\citation{b7}
\citation{b8}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Clustering Analysis}{1}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Databases}{1}{subsection.2.1}}
\citation{b9}
\citation{b10}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces TSNE visualization of multiple databases in a reduced 2D feature-space. Cluster indices are assigned to random colors. (a) personal\_faces. (b) LFW. (c) MUCT.\relax }}{2}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tsneview}{{1}{2}{TSNE visualization of multiple databases in a reduced 2D feature-space. Cluster indices are assigned to random colors. (a) personal\_faces. (b) LFW. (c) MUCT.\relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Test subset creation pipeline. In the first step, raw images are loaded from the database. Then, OpenCV's cascade classifier is applied on the images to extract faces and resize them to $160\times 160$. Afterwards, we evaluate FaceNet on each face picture to get the embeddings (feature-vectors). In each run, we sample a random subset of embeddings and feed it to clustering methods.\relax }}{2}{figure.caption.2}}
\newlabel{pipeline}{{2}{2}{Test subset creation pipeline. In the first step, raw images are loaded from the database. Then, OpenCV's cascade classifier is applied on the images to extract faces and resize them to $160\times 160$. Afterwards, we evaluate FaceNet on each face picture to get the embeddings (feature-vectors). In each run, we sample a random subset of embeddings and feed it to clustering methods.\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}Experiments}{2}{subsection.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-C}}Results}{2}{subsection.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Plots of \textit  {ARI} scores \textit  {vs.} hyper-parameters. \textit  {personal\_faces}, LFW and MUCT are displayed in red, green and blue, respectively. The vertical axis indicates the score value, and the horizontal axis indicates the method-specific parameter values. (a) Mean-shift. (b) DBSCAN. \relax }}{3}{figure.caption.4}}
\newlabel{parameter_plot}{{3}{3}{Plots of \textit {ARI} scores \textit {vs.} hyper-parameters. \textit {personal\_faces}, LFW and MUCT are displayed in red, green and blue, respectively. The vertical axis indicates the score value, and the horizontal axis indicates the method-specific parameter values. (a) Mean-shift. (b) DBSCAN. \relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Conclusion}{3}{section.3}}
\bibcite{b1}{1}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Average $ARI$ score of all methods on different databases (together with their standard deviations). Each row represents a clustering technique with a specific parameter value, while each column is a database. In DBSCAN rows, $eps$ means the maximum possible distance between points in the same cluster. In mean-shift rows, $bw$ stands for bandwidth. \relax }}{4}{table.caption.3}}
\newlabel{scores_table}{{I}{4}{Average $ARI$ score of all methods on different databases (together with their standard deviations). Each row represents a clustering technique with a specific parameter value, while each column is a database. In DBSCAN rows, $eps$ means the maximum possible distance between points in the same cluster. In mean-shift rows, $bw$ stands for bandwidth. \relax }{table.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Different people assigned to the same k-means cluster. Notice the face similarity: the nose and mouth shape are close; also both use glasses.\relax }}{4}{figure.caption.5}}
\newlabel{wrong_similar}{{4}{4}{Different people assigned to the same k-means cluster. Notice the face similarity: the nose and mouth shape are close; also both use glasses.\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Different people assigned to the same group by agglomerative clustering. Both people share the same ethnical group, though they are clearly distinguishable by humans.\relax }}{4}{figure.caption.6}}
\newlabel{wrong_ethnical}{{5}{4}{Different people assigned to the same group by agglomerative clustering. Both people share the same ethnical group, though they are clearly distinguishable by humans.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Same person assigned to different clusters because of sunglasses. As humans, we clearly see that the hairstyle, the smile and the nose shapes are all preserved in both pictures. This mistake was made by all methods, which shows that the corresponding FaceNet embeddings are intrinsically distant.\relax }}{4}{figure.caption.7}}
\newlabel{wrong_split}{{6}{4}{Same person assigned to different clusters because of sunglasses. As humans, we clearly see that the hairstyle, the smile and the nose shapes are all preserved in both pictures. This mistake was made by all methods, which shows that the corresponding FaceNet embeddings are intrinsically distant.\relax }{figure.caption.7}{}}
\bibcite{b2}{2}
\bibcite{b3}{3}
\bibcite{b4}{4}
\bibcite{b5}{5}
\bibcite{b6}{6}
\bibcite{b7}{7}
\bibcite{b8}{8}
\bibcite{b9}{9}
\bibcite{b10}{10}
\@writefile{toc}{\contentsline {section}{References}{5}{section*.8}}
